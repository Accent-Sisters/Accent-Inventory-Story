{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936a006b",
   "metadata": {},
   "source": [
    "## â†’ Chapter Three  \n",
    "\n",
    "*Battle with the Forbidden Databases, Seleniumâ€™s Brave Charge Ends in Defeat*\n",
    " \n",
    "ğŸ”ºSince scraping bookschina.com worked, I assumed my plan would succeed. I scanned all the books over several daysâ€”about 10 hours total. Then I returned to chinabooks.com to scrape the remaining data.  \n",
    "\n",
    "ğŸ”ºBut this time, the request returned nothing. The website had changed. On the homepage, a banner stated:  \n",
    "\n",
    "> â€œè¿‘æ—¥ï¼Œæˆ‘å¸æ¥åˆ°å¤šèµ·ä¸¾æŠ¥ï¼Œæœ‰ä¸æ³•åˆ†å­ä½¿ç”¨æˆ‘å…¬å¸åä¹‰ä»¥å¯¹å¤–æä¾›åˆ·å•ä¸šåŠ¡ç­‰å½¢å¼å®æ–½ç½‘ç»œè¯ˆéª—ï¼Œæˆ‘å¸ä¸¥æ­£å£°æ˜ï¼Œä»æœªä»¥ä»»ä½•æ–¹å¼ç»„ç»‡å¼€å±•åˆ·å•ä¸šåŠ¡ï¼Œäº¦æœªæˆæƒä»»ä½•å•ä½ã€ä¸ªäººå¼€å±•ä¸Šè¿°ä¸šåŠ¡ï¼Œè¯·è°¨é˜²è¯ˆéª— >>â€  \n",
    "> **Translation**: Recently, our company received multiple reports of fraudsters falsely claiming to offer fake transaction services in our name. We solemnly declare that we have never engaged in such activities nor authorized any third party to do so. Please beware of scams.  \n",
    "\n",
    "â†’ <img src=\"../images/0301.png\" alt=\"Chinabooks banner warning against fraud\" width=\"400px\">\n",
    "\n",
    "\n",
    "ğŸ”ºI then used a plug in called Selenium, a Python library that allows the code to open a web browser and simulate real interactions (like clicking, typing, etc.) and specific delays to test whether it was a bot detection issue. The site still returned no results. Below is a brief tutorial using my test file as an example to use Selenium to Simulate a Single ISBN Search.\n",
    "\n",
    "---\n",
    "## â†’ ç¬¬ä¸‰å› \n",
    "\n",
    "*å¤§æˆ˜ç¦ä¹¦æ•°æ®åº“ï¼Œè‡ªåŠ¨ä¾ èµ›ç³å¨œå‹‡é—¯å¥‡é—¨é˜µ*  \n",
    "\n",
    "ğŸ”ºç”±äºæ­¤å‰æˆåŠŸçˆ¬å–äº† bookschina.comï¼Œæˆ‘ä»¥ä¸ºæ•´ä¸ªæµç¨‹å·²ç»å¯ä»¥é¡ºåˆ©è·‘é€šã€‚äºæ˜¯æˆ‘èŠ±äº†å‡ å¤©æ—¶é—´æ‰«æäº†æ‰€æœ‰ä¹¦ç±ï¼Œæ€»å…±èŠ±äº†å¤§çº¦10å°æ—¶ã€‚æ¥ç€æˆ‘å›åˆ° chinabooks.com ç»§ç»­çˆ¬å–å‰©ä¸‹çš„æ•°æ®ã€‚  \n",
    "\n",
    "ğŸ”ºä½†è¿™ä¸€æ¬¡ï¼Œè¯·æ±‚è¿”å›äº†ç©ºå†…å®¹ã€‚ç½‘ç«™å·²ç»å‘ç”Ÿäº†å˜åŒ–ã€‚åœ¨é¦–é¡µé¡¶éƒ¨å‡ºç°äº†ä¸€æ¡å…¬å‘Šï¼š  \n",
    "\n",
    "> â€œè¿‘æ—¥ï¼Œæˆ‘å¸æ¥åˆ°å¤šèµ·ä¸¾æŠ¥ï¼Œæœ‰ä¸æ³•åˆ†å­ä½¿ç”¨æˆ‘å…¬å¸åä¹‰ä»¥å¯¹å¤–æä¾›åˆ·å•ä¸šåŠ¡ç­‰å½¢å¼å®æ–½ç½‘ç»œè¯ˆéª—ï¼Œæˆ‘å¸ä¸¥æ­£å£°æ˜ï¼Œä»æœªä»¥ä»»ä½•æ–¹å¼ç»„ç»‡å¼€å±•åˆ·å•ä¸šåŠ¡ï¼Œäº¦æœªæˆæƒä»»ä½•å•ä½ã€ä¸ªäººå¼€å±•ä¸Šè¿°ä¸šåŠ¡ï¼Œè¯·è°¨é˜²è¯ˆéª— >>â€  \n",
    "\n",
    "â†’ <img src=\"../images/0301.png\" alt=\"chinabooksåè¯ˆéª—è­¦ç¤ºæ¨ªå¹…æˆªå›¾\" width=\"400px\">\n",
    "\n",
    "\n",
    "ğŸ”ºæˆ‘éšåä½¿ç”¨äº†ä¸€ä¸ªåä¸º Selenium çš„æ’ä»¶ï¼Œå®ƒæ˜¯ä¸€ä¸ª Python åº“ï¼Œå¯ä»¥è®©ä»£ç æ‰“å¼€ç½‘é¡µæµè§ˆå™¨å¹¶æ¨¡æ‹ŸçœŸå®ç”¨æˆ·çš„æ“ä½œï¼ˆå¦‚ç‚¹å‡»ã€è¾“å…¥ç­‰ï¼‰ï¼Œè¿˜èƒ½è®¾ç½®ç­‰å¾…æ—¶é—´ã€‚æˆ‘å°è¯•ä½¿ç”¨äººå·¥è¡Œä¸ºæ¨¡æ‹Ÿæ¥æµ‹è¯•æ˜¯å¦æ˜¯åçˆ¬æœºåˆ¶çš„é—®é¢˜ã€‚ä½†å³ä½¿å¦‚æ­¤ï¼Œç½‘ç«™ä¾ç„¶æ²¡æœ‰è¿”å›ç»“æœã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€è¦æ•™ç¨‹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨æˆ‘çš„æµ‹è¯•æ–‡ä»¶ï¼Œé€šè¿‡ Selenium æ¨¡æ‹Ÿå•ä¸ªISBNæœç´¢æ“ä½œã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d095da",
   "metadata": {},
   "source": [
    "### **â†’ Using Selenium to Simulate a Real Browser for Scraping**  \n",
    "\n",
    "**â†’ 1. What is Selenium?**  \n",
    "Selenium is a Python library that allows you to automate web browser interactions just like a human would. It opens a browser, clicks buttons, types text, and waits for content to load.  \n",
    "It is especially useful when dealing with JavaScript-heavy websites or sites that block traditional scraping methods using `requests`, like I just did with Beautiful Soup and request.\n",
    "\n",
    "\n",
    "**â†’ 2. Install Selenium**  \n",
    "install Selenium by running the following code: \n",
    "```bash\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "**â†’ 3. Download ChromeDriver**\n",
    "\n",
    "1. Go to: [https://googlechromelabs.github.io/chrome-for-testing/](https://googlechromelabs.github.io/chrome-for-testing/)\n",
    "2. Check current Chrome version (type `chrome://version` in your browser). (Make sure the current Chrome browser version matches the ChromeDriver version.)\n",
    "3. Download the matching ChromeDriver for the operating system.\n",
    "4. Unzip the file and place it somewhere accessible, like `Downloads/` folder, and copy the file path.\n",
    "\n",
    "\n",
    "**â†’ 4. Run the test script**\n",
    "\n",
    "After setting up for Selenium, I used the following code to:\n",
    "\n",
    "- Load an ISBN from a CSV file  \n",
    "- Opens `bookschina.com`  \n",
    "- Adds a cookie to force desktop mode  \n",
    "- Searches for the ISBN in the search bar  \n",
    "- Saves the resulting HTML for debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175502b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "base_url = \"https://www.bookschina.com/book_find2/?stp=\"\n",
    "driver_path = r\"C:/Users/aliso/Downloads/chromedriver-win64/chromedriver.exe\"\n",
    "service = ChromeService(executable_path=driver_path)\n",
    "options = Options()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 ...\")\n",
    "\n",
    "df = pd.read_csv('../data/scannedResults.csv')\n",
    "isbn = str(df['CODECONTENT'][7])\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Add cookie to force desktop version\n",
    "driver.get(\"https://www.bookschina.com/\")\n",
    "driver.add_cookie({\"name\": \"isPc\", \"value\": \"yes\", \"path\": \"/\", \"domain\": \"www.bookschina.com\"})\n",
    "driver.get(\"https://www.bookschina.com/\")\n",
    "\n",
    "# Simulate search\n",
    "time.sleep(2)\n",
    "search_input = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"keyword\")))\n",
    "search_input.click()\n",
    "time.sleep(0.5)\n",
    "search_input.clear()\n",
    "search_input.send_keys(isbn)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Save HTML\n",
    "time.sleep(10)\n",
    "with open(\"debug_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(driver.page_source)\n",
    "print(\"âœ… Saved page content to debug_page.html\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd408c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ”ºHowever, this also did not work. Selenium successfully opened the page on the browser but wasn't able to extract the html information. \n",
    "\n",
    "â†’ <img src=\"../images/0302.png\" alt=\"robots.txt page\" width=\"400px\">\n",
    "\n",
    "ğŸ”ºMy friend reminded me to check the site's robots.txt file. robots.txt is a file that websites use to control how web crawlers or bots interact with their pages. It can block certain pages from being accessed, or disallow all scraping entirely. The one at chinabooks.com now blocks scraping.\n",
    "\n",
    "â†’ <img src=\"../images/0303.png\" alt=\"robots.txt explanation\" width=\"400px\">\n",
    "\n",
    "ğŸ”ºThe same goes for Douban (è±†ç“£), a Chinese social media and database platform for books, films, music, and cultural reviews. It's often considered the Chinese equivalent of Goodreads, but also includes user-generated reviews, tags, and ratings. In Douban's case, it uses a strict login and rate-limiting to prevent scraping or even manual information extraction in bulk. Douban also requires a Chinese phone number for full access and authentication, which, ultimately prevents people trying to bypass their anti-bot mechanism illegally, because Chinese phone numbers are tied to each citizens' real name and state issued ID number by law.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88513320",
   "metadata": {},
   "source": [
    "\n",
    "### **â†’ ä½¿ç”¨ Selenium æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¿›è¡Œçˆ¬å–**  \n",
    "\n",
    "**â†’ 1. ä»€ä¹ˆæ˜¯ Seleniumï¼Ÿ**  \n",
    "Selenium æ˜¯ä¸€ä¸ª Python åº“ï¼Œå¯ä»¥æ¨¡æ‹ŸçœŸå®ç”¨æˆ·åœ¨ç½‘é¡µæµè§ˆå™¨ä¸Šçš„æ“ä½œï¼Œæ¯”å¦‚æ‰“å¼€ç½‘é¡µã€ç‚¹å‡»æŒ‰é’®ã€è¾“å…¥æ–‡å­—ã€ç­‰å¾…å†…å®¹åŠ è½½ç­‰ã€‚  \n",
    "å½“ç½‘ç«™ä½¿ç”¨å¤§é‡ JavaScript æˆ–é€šè¿‡ `requests`ï¼ˆå¦‚æˆ‘ä¹‹å‰ç”¨ Beautiful Soup æ‰€åšçš„ï¼‰é˜»æ­¢ä¼ ç»Ÿçˆ¬è™«æ—¶ï¼ŒSelenium å°±éå¸¸æœ‰ç”¨ã€‚\n",
    "\n",
    "\n",
    "**â†’ 2. å®‰è£… Selenium**  \n",
    "é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£… Seleniumï¼š  \n",
    "```bash\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "**â†’ 3. ä¸‹è½½ ChromeDriver**\n",
    "\n",
    "æ‰“å¼€ç½‘ç«™ï¼šhttps://googlechromelabs.github.io/chrome-for-testing/\n",
    "\n",
    "åœ¨æµè§ˆå™¨åœ°å€æ è¾“å…¥ chrome://versionï¼ŒæŸ¥çœ‹å½“å‰ Chrome æµè§ˆå™¨ç‰ˆæœ¬ã€‚ï¼ˆç¡®ä¿ä¸‹è½½çš„ ChromeDriver ä¸ Chrome æµè§ˆå™¨ç‰ˆæœ¬åŒ¹é…ã€‚ï¼‰\n",
    "\n",
    "ä¸‹è½½ä¸ä½ çš„æ“ä½œç³»ç»Ÿç›¸åŒ¹é…çš„ ChromeDriverã€‚\n",
    "\n",
    "è§£å‹ä¸‹è½½çš„æ–‡ä»¶ï¼Œå°†å…¶æ”¾åˆ°ä¸€ä¸ªæ–¹ä¾¿è®¿é—®çš„ä½ç½®ï¼ˆä¾‹å¦‚ Downloads/ æ–‡ä»¶å¤¹ï¼‰ï¼Œå¹¶å¤åˆ¶å®ƒçš„å®Œæ•´æ–‡ä»¶è·¯å¾„å¤‡ç”¨ã€‚\n",
    "\n",
    "**â†’ 4. è¿è¡Œæµ‹è¯•è„šæœ¬**\n",
    "\n",
    "åœ¨å®Œæˆ Selenium è®¾ç½®åï¼Œæˆ‘ä½¿ç”¨ä»¥ä¸‹ä»£ç å®ç°äº†ä»¥ä¸‹æ“ä½œï¼š\n",
    "\n",
    "- ä» CSV æ–‡ä»¶ä¸­è¯»å–ä¸€ä¸ª ISBN\n",
    "- æ‰“å¼€ bookschina.com ç½‘ç«™\n",
    "- æ·»åŠ  cookie å¼ºåˆ¶æ˜¾ç¤ºæ¡Œé¢ç‰ˆç½‘é¡µ\n",
    "- åœ¨æœç´¢æ ä¸­è¾“å…¥ ISBN å¹¶æ‰§è¡Œæœç´¢\n",
    "- ä¿å­˜è¿”å›çš„ç½‘é¡µ HTML ä»¥ä¾›è°ƒè¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e95f0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "base_url = \"https://www.bookschina.com/book_find2/?stp=\"\n",
    "driver_path = r\"C:/Users/aliso/Downloads/chromedriver-win64/chromedriver.exe\"\n",
    "service = ChromeService(executable_path=driver_path)\n",
    "options = Options()\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 ...\")\n",
    "\n",
    "df = pd.read_csv('../data/scannedResults.csv')\n",
    "isbn = str(df['CODECONTENT'][7])\n",
    "\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Add cookie to force desktop version\n",
    "driver.get(\"https://www.bookschina.com/\")\n",
    "driver.add_cookie({\"name\": \"isPc\", \"value\": \"yes\", \"path\": \"/\", \"domain\": \"www.bookschina.com\"})\n",
    "driver.get(\"https://www.bookschina.com/\")\n",
    "\n",
    "# Simulate search\n",
    "time.sleep(2)\n",
    "search_input = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"keyword\")))\n",
    "search_input.click()\n",
    "time.sleep(0.5)\n",
    "search_input.clear()\n",
    "search_input.send_keys(isbn)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "\n",
    "# Save HTML\n",
    "time.sleep(10)\n",
    "with open(\"debug_page.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(driver.page_source)\n",
    "print(\"âœ… Saved page content to debug_page.html\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9df44f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "ğŸ”ºç„¶è€Œï¼Œè¿™ä¾ç„¶æ²¡æœ‰æˆåŠŸã€‚Selenium è™½ç„¶æˆåŠŸæ‰“å¼€äº†æµè§ˆå™¨é¡µé¢ï¼Œä½†æ— æ³•æå– HTML å†…å®¹ã€‚  \n",
    "\n",
    "â†’ <img src=\"../images/0302.png\" alt=\"robots.txt é¡µé¢æˆªå›¾\" width=\"400px\">  \n",
    "\n",
    "ğŸ”ºæœ‹å‹æé†’æˆ‘æ£€æŸ¥ç½‘ç«™çš„ robots.txt æ–‡ä»¶ã€‚`robots.txt` æ˜¯ç½‘ç«™ç”¨äºæ§åˆ¶ç½‘ç»œçˆ¬è™«æˆ–æœºå™¨äººè®¿é—®è§„åˆ™çš„æ–‡ä»¶ã€‚ç½‘ç«™å¯ä»¥é€šè¿‡å®ƒç¦æ­¢çˆ¬å–ç‰¹å®šé¡µé¢ï¼Œç”šè‡³å®Œå…¨æ‹’ç»æ‰€æœ‰çˆ¬è™«è®¿é—®ã€‚chinabooks.com çš„ robots.txt æ–‡ä»¶ç°åœ¨å·²ç»æ˜ç¡®ç¦æ­¢äº†çˆ¬è™«è¡Œä¸ºã€‚\n",
    "\n",
    "â†’ <img src=\"../images/0303.png\" alt=\"robots.txt è¯´æ˜æˆªå›¾\" width=\"400px\">  \n",
    "\n",
    "ğŸ”ºè±†ç“£ï¼ˆDoubanï¼‰ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è±†ç“£æ˜¯ä¸€ä¸ªä¸­æ–‡ç¤¾äº¤åª’ä½“å’Œæ•°æ®åº“å¹³å°ï¼ŒåŒ…å«å›¾ä¹¦ã€ç”µå½±ã€éŸ³ä¹å’Œæ–‡åŒ–è¯„è®ºå†…å®¹ã€‚å®ƒå¸¸è¢«è§†ä¸ºä¸­å›½ç‰ˆ Goodreadsï¼ŒåŒæ—¶æä¾›ç”¨æˆ·ç”Ÿæˆçš„è¯„è®ºã€æ ‡ç­¾å’Œè¯„åˆ†ç­‰åŠŸèƒ½ã€‚åœ¨è±†ç“£çš„æƒ…å†µä¸‹ï¼Œå®ƒé€šè¿‡ä¸¥æ ¼çš„ç™»å½•æœºåˆ¶å’Œè®¿é—®é¢‘ç‡é™åˆ¶æ¥é˜²æ­¢çˆ¬è™«ï¼Œç”šè‡³è¿äººå·¥å¤§æ‰¹é‡æŸ¥çœ‹ä¿¡æ¯ä¹Ÿä¼šè¢«é™åˆ¶ã€‚æ­¤å¤–ï¼Œè±†ç“£è¦æ±‚ç”¨æˆ·å¿…é¡»ç»‘å®šä¸­å›½å¤§é™†æ‰‹æœºå·è¿›è¡Œå®Œæ•´èº«ä»½è®¤è¯ã€‚ç”±äºä¸­å›½æ‰‹æœºå·å¿…é¡»é€šè¿‡èº«ä»½è¯å®ååˆ¶ç™»è®°ï¼Œè¿™ä¸€æœºåˆ¶ä»æ ¹æœ¬ä¸Šé˜»æ­¢äº†å¤§å¤šæ•°ä¼å›¾ç»•è¿‡åçˆ¬æœºåˆ¶çš„éæ³•è¡Œä¸ºã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa76f8e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
