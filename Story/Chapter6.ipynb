{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d638ea",
   "metadata": {},
   "source": [
    "## â†’ Chapter Six \n",
    "\n",
    "**Deciphering the broken pinyin, Completing the Epic Merge**  \n",
    "\n",
    "ðŸ”ºOne of the challanges in data cleaning was that, global databases like ISBNdb and isbnsearch.org often returned Chinese book metadata in **pinyin**(the phonetic romanization of Chinese) and not in readable Chinese characters. To fix this, I used a Python library called **pinyin2hanzi** which converts pinyin text into the most likely Chinese characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a62cd3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Pinyin2Hanzi import DefaultDagParams, dag\n",
    "\n",
    "# initialize pinyin converter\n",
    "dagparams = DefaultDagParams()\n",
    "\n",
    "# helper function to convert pinyin string to hanzi if score > 0.1\n",
    "def convert_pinyin_to_hanzi(pinyin_string):\n",
    "    pinyin_list = pinyin_string.strip().lower().split()\n",
    "    try:\n",
    "        result = dag(dagparams, pinyin_list, path_num=5)\n",
    "        for item in result:\n",
    "            if item.score > 0.1:\n",
    "                return ''.join(item.path)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# --- Convert isbndbResults.csv ---\n",
    "isbndb_df = pd.read_csv('isbndbResults.csv')\n",
    "isbndb_df['converted_title'] = isbndb_df['title'].astype(str).apply(convert_pinyin_to_hanzi)\n",
    "\n",
    "# --- Convert zoteroExport.csv ---\n",
    "zotero_df = pd.read_csv('zoteroExport.csv')\n",
    "\n",
    "# process title\n",
    "zotero_df['converted_title'] = zotero_df['Title'].astype(str).apply(convert_pinyin_to_hanzi)\n",
    "\n",
    "# clean ISBN column (keep first 17 characters, remove hyphens)\n",
    "zotero_df['ISBN'] = zotero_df['ISBN'].astype(str).str[:17].str.replace('-', '', regex=False)\n",
    "\n",
    "# result DataFrames\n",
    "isbndbConverted = isbndb_df\n",
    "zoteroConverted = zotero_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990a5d5",
   "metadata": {},
   "source": [
    "ðŸ”ºThen, I created a script to merge the book data collected from the four sources into a single, structured dataset formatted to match the fields required for Shopify product import.\n",
    "- **ISBNdb** \n",
    "- **Zotero** \n",
    "- **Dangdang.com** \n",
    "- **isbnsearch.org**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd201f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
