{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d638ea",
   "metadata": {},
   "source": [
    "## â†’ Chapter Six \n",
    "\n",
    "**Deciphering the broken pinyin, Completing the Epic Merge**  \n",
    "\n",
    "ğŸ”ºOne of the challanges in data cleaning was that, global databases like ISBNdb and isbnsearch.org often returned Chinese book metadata in **pinyin**(the phonetic romanization of Chinese) and not in readable Chinese characters. To fix this, I used a Python library called **pinyin2hanzi** which converts pinyin text into the most likely Chinese characters. \n",
    "\n",
    "ğŸ”ºWith the code below, I was able to transform some of the titles in pinyin into Chinese and clean up the title values from dangdang.com best as I could.\n",
    "\n",
    "ğŸ”ºSince there are also English titles mixed in, I specified the confidence score to be > 0.05 to select only the accurate results \n",
    "\n",
    "---\n",
    "## â†’ ç¬¬å…­ç« \n",
    "\n",
    "**ç ´è§£ç ´ç¢æ‹¼éŸ³ï¼Œå®Œæˆå¤§åˆå¹¶**\n",
    "\n",
    "ğŸ”ºæ•°æ®æ¸…æ´—è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªéš¾é¢˜æ˜¯ï¼Œåƒ ISBNdb å’Œ isbnsearch.org è¿™æ ·çš„å…¨çƒæ•°æ®åº“ç»å¸¸è¿”å›çš„æ˜¯ä¸­æ–‡ä¹¦ç±çš„ **æ‹¼éŸ³**ï¼ˆä¸­æ–‡çš„éŸ³è¯‘ï¼‰ï¼Œè€Œä¸æ˜¯å¯è¯»çš„ä¸­æ–‡å­—ç¬¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ªåä¸º **pinyin2hanzi** çš„ Python åº“ï¼Œå®ƒå¯ä»¥å°†æ‹¼éŸ³è½¬æ¢ä¸ºæœ€æœ‰å¯èƒ½çš„ä¸­æ–‡å­—ç¬¦ã€‚\n",
    "\n",
    "ğŸ”ºé€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘æˆåŠŸåœ°å°†éƒ¨åˆ†æ‹¼éŸ³æ ‡é¢˜è½¬æ¢æˆäº†ä¸­æ–‡ï¼Œå¹¶å°½å¯èƒ½æ¸…ç†äº†ä»å½“å½“ç½‘è·å–çš„æ ‡é¢˜å­—æ®µã€‚\n",
    "\n",
    "ğŸ”ºç”±äºæ•°æ®ä¸­è¿˜æ··æ‚æœ‰è‹±æ–‡æ ‡é¢˜ï¼Œæˆ‘è®¾ç½®äº†ç½®ä¿¡åˆ†æ•°é˜ˆå€¼ï¼ˆscore > 0.05ï¼‰ï¼Œä»¥ç­›é€‰å‡ºæ›´å‡†ç¡®çš„ç»“æœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a62cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Pinyin2Hanzi import DefaultDagParams, dag\n",
    "\n",
    "# initialize pinyin converter\n",
    "dagparams = DefaultDagParams()\n",
    "\n",
    "# helper function to convert pinyin string to hanzi if score > 0.1\n",
    "def convert_pinyin_to_hanzi(pinyin_string):\n",
    "    pinyin_list = pinyin_string.strip().lower().split()\n",
    "    try:\n",
    "        result = dag(dagparams, pinyin_list, path_num=5)\n",
    "        for item in result:\n",
    "            if item.score > 0.05:\n",
    "                return ''.join(item.path)\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# --- Convert isbndbResults.csv ---\n",
    "isbndb_df = pd.read_csv('../data/isbndbResults.csv')\n",
    "isbndb_df['converted_title'] = isbndb_df['title'].astype(str).apply(convert_pinyin_to_hanzi)\n",
    "\n",
    "# --- Convert zoteroExport.csv ---\n",
    "zotero_df = pd.read_csv('../data/zoteroExport.csv')\n",
    "\n",
    "# process title\n",
    "zotero_df['converted_title'] = zotero_df['Title'].astype(str).apply(convert_pinyin_to_hanzi)\n",
    "\n",
    "# clean ISBN column (keep first 17 characters, remove hyphens)\n",
    "zotero_df['ISBN'] = zotero_df['ISBN'].astype(str).str[:17].str.replace('-', '', regex=False)\n",
    "\n",
    "# result DataFrames\n",
    "isbndbConverted = isbndb_df\n",
    "zoteroConverted = zotero_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33491b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the CSV\n",
    "dangdang = pd.read_csv('../data/dangdangResults.csv')\n",
    "\n",
    "# Clean title: remove all full-width parentheses ï¼ˆï¼‰ and ã€ã€‘\n",
    "def clean_title(title):\n",
    "    if pd.isna(title):\n",
    "        return title\n",
    "    title = re.sub(r'ï¼ˆ.*?ï¼‰', '', title)\n",
    "    title = re.sub(r'ã€.*?ã€‘', '', title)\n",
    "    return title.strip()\n",
    "\n",
    "# Apply cleaning\n",
    "dangdang['title'] = dangdang['title'].astype(str).apply(clean_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990a5d5",
   "metadata": {},
   "source": [
    "ğŸ”ºHowever, a lot of these works' titles are too complicated for the library to convert, so I decided to do a manual edit on the final result to: transform the rest of the pinyin and clean the rest of the dangdang titles. \n",
    "\n",
    "ğŸ”ºThen, I created a script to merge the book data collected from the three sources into a single, structured dataset formatted to match the fields required for Shopify product import.\n",
    "- **ISBNdb** \n",
    "- **Zotero** \n",
    "- **Dangdang.com** \n",
    "\n",
    "---\n",
    "ğŸ”ºç„¶è€Œï¼Œè¿™äº›ä½œå“ä¸­æœ‰è®¸å¤šæ ‡é¢˜è¿‡äºå¤æ‚ï¼Œpinyin2hanzi åº“æ— æ³•å‡†ç¡®è½¬æ¢ï¼Œå› æ­¤æˆ‘å†³å®šåœ¨æœ€ç»ˆç»“æœä¸­è¿›è¡Œäººå·¥ä¿®æ­£ï¼šæ‰‹åŠ¨è½¬æ¢å‰©ä½™çš„æ‹¼éŸ³ï¼Œå¹¶æ¸…ç†å½“å½“ç½‘ä¸­å‰©ä¸‹çš„æ ‡é¢˜ã€‚\n",
    "\n",
    "ğŸ”ºéšåï¼Œæˆ‘ç¼–å†™äº†ä¸€ä¸ªè„šæœ¬ï¼Œå°†ä»ä¸‰ä¸ªæ¥æºæ”¶é›†çš„å›¾ä¹¦æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªç»“æ„åŒ–æ•°æ®é›†ï¼Œæ ¼å¼ä¸ Shopify äº§å“å¯¼å…¥æ‰€éœ€çš„å­—æ®µä¸€è‡´ï¼š\n",
    "- **ISBNdb**  \n",
    "- **Zotero**  \n",
    "- **å½“å½“ç½‘ï¼ˆDangdang.comï¼‰**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e057c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('../data/shopifyTemplate.csv')\n",
    "dangdang = pd.read_csv('../data/dangdangResults.csv')\n",
    "zotero = pd.read_csv('../data/zoteroExport.csv')\n",
    "isbndb = pd.read_csv('../data/isbndbResults.csv')\n",
    "\n",
    "# Clean up ISBNs to match format\n",
    "zotero['ISBN'] = zotero['ISBN'].astype(str).str.replace('-', '').str[:13]\n",
    "isbndb['isbn_searched'] = isbndb['isbn_searched'].astype(str).str[:13]\n",
    "dangdang['isbn'] = dangdang['isbn'].astype(str).str[:13]\n",
    "\n",
    "# Helper function to get first non-null value from priority list\n",
    "def get_priority_value(isbn, zot_col, isbndb_col, dang_col):\n",
    "    if isbn in zotero['ISBN'].values:\n",
    "        return zotero.loc[zotero['ISBN'] == isbn, zot_col].values[0]\n",
    "    elif isbn in isbndb['isbn_searched'].values:\n",
    "        return isbndb.loc[isbndb['isbn_searched'] == isbn, isbndb_col].values[0]\n",
    "    elif isbn in dangdang['isbn'].values:\n",
    "        return dangdang.loc[dangdang['isbn'] == isbn, dang_col].values[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply field population based on hierarchy\n",
    "df['Variant Barcode'] = df['Variant Barcode'].astype(str).str[:13]  # Ensure consistency\n",
    "df['Title'] = df['Variant Barcode'].apply(lambda x: get_priority_value(x, 'Title', 'title', 'title'))\n",
    "df['Image Src'] = df['Variant Barcode'].apply(lambda x: isbndb.loc[isbndb['isbn_searched'] == x, 'image'].values[0]\n",
    "                                              if x in isbndb['isbn_searched'].values else None)\n",
    "\n",
    "# Construct Body (HTML)\n",
    "def build_html_body(isbn):\n",
    "    if isbn in zotero['ISBN'].values:\n",
    "        row = zotero.loc[zotero['ISBN'] == isbn].iloc[0]\n",
    "        year = row.get('Publication Year', '')\n",
    "        author = row.get('Author', '')\n",
    "        publisher = row.get('Publisher', '')\n",
    "        pages = row.get('Num Pages', '')\n",
    "        description = row.get('Abstract Note', '')\n",
    "    elif isbn in isbndb['isbn_searched'].values:\n",
    "        row = isbndb.loc[isbndb['isbn_searched'] == isbn].iloc[0]\n",
    "        year = row.get('date_published', '')\n",
    "        author = row.get('authors', '')\n",
    "        publisher = row.get('publisher', '')\n",
    "        pages = row.get('pages', '')\n",
    "        description = row.get('synopsis', '')\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    return f\"<p>Year: {year}</p><p>Author: {author}</p><p>Publisher: {publisher}</p><p>Pages: {pages}</p><p>Description: {description}</p>\"\n",
    "\n",
    "df['Body (HTML)'] = df['Variant Barcode'].apply(build_html_body)\n",
    "df.to_csv('finalInventory.csv', index=False, encoding='utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
